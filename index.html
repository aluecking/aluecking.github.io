<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Home of Andy Lücking</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Andy Lücking</strong></a>
									<ul class="icons">
										<li><a href="https://orcid.org/0000-0002-5070-2233" target="_blank" class="icon brands fa-orcid"><span class="label">ORCID</span></a></li>
										<li><a href="https://www.researchgate.net/profile/Andy-Luecking" target="_blank" class="icon brands fa-researchgate"><span class="label">ResearchGate</span></a></li>
										<li><a href="https://github.com/aluecking" target="_blank" class="icon brands fa-github"><span class="label">Github</span></a></li>
									</ul>
								</header>

							<!-- Banner -->
								<section id="banner">
									<div class="content">
										<header>
											<h2>Welcome</h2>
										</header>
										<p>I'm a theoretical and computational linguistic whose research contributes to a linguistic theory of human communication, that is, face-to-face interaction within and beyond single sentences, with particular attention to various kinds of gestures and cognitive modeling. This involves adapting dynamic dialogue semantics, developing multimodal grammar extensions, occasionally revising traditional linguistic theories (e.g., quantification or pointing), utilizing corpora and computational methods/text processing, and taking an overarching cognitive perspective, such as grounding linguistic context in memory states. My areas of interest include &quot;traditional&quot; linguistic phenomena such as demonstrative pronouns, plurality, quantification, and reference.</p>
										
										<p>My theoretical contributions include a semantic theory of plurality and quantification (<a href="https://doi.org/10.3765/sp.15.4" target="_blank">RTT</a>), a spatial semantics of pointing gestures (part of my habilitation thesis &mdash; but see the <a href="#talks"><i>Pointing</i> presentation</a> below), and a classifier-based iconic gesture semantics (see the <a href="https://ling.auf.net/lingbuzz/007916" target="_blank"><i>Iconic Gesture Semantics</i> preprint</a> at lingbuzz or <a href="https://arxiv.org/abs/2404.18708" target="_blank">arxiv</a>). In recent joint work I contribute to integrating dialogue semantics with memory and brain structures and processes.</p>
										
										<p>I received a PhD in linguistics (Dr. phil.) in 2011 at <a href="https://www.uni-bielefeld.de/" target="_blank">Bielefeld University</a> on iconicity and iconic gestures. I defended my habilitation in 2022 on <em>Aspects of Multimodal Communication</em> at the <a href="http://www.llf.cnrs.fr/" target="_blank">Laboratoire de Linguistique Formelle</a> (LLF) at <a href="https://u-paris.fr/en/" target="_blank">Université Paris Cité</a> in a postdoc research position.</p>
										<p>Currently I'm a Privatdozent at <a href="https://www.uni-frankfurt.de/" target="_blank">Goethe University Frankfurt</a>, <a href="https://www.texttechnologylab.org/" target="_blank">Text Technology Lab</a>.</p>
									</div>
									<span class="image object">
										<img src="images/AL-2019_optim.jpg" alt="" style="width: 40%;height: 95%;overflow: hidden">
									</span>
								</section>




							<!-- Section -->
								<section>
									<header class="major">
										<h2 id="publications">Publications</h2>
									<p>Below a selection of works I like most. For the full list of publications please see the <i>Publications</i> menu at <a href="https://www.texttechnologylab.org/team/andy-luecking/" target="_blank">the TTLab page</a>.</p>
									</header>
																		
									<div class="posts">
										<article>
<!--											<a href="#" class="image"><img src="images/vr-move.jpg" alt="" /></a>
											<h3>GeMDiS</h3>-->
											<p>Andy Lücking and Jonathan Ginzburg. <strong>Leading voices: Dialogue semantics, cognitive science, and the polyphonic structure of multimodal interaction</strong>. Language and Cognition , Volume 15 , Issue 1 , January 2023 , pp. 148&ndash;172, DOI: <a href="https://doi.org/10.1017/langcog.2022.30" target="_blank">10.1017/langcog.2022.30</a>. (<a href="https://www.researchgate.net/publication/365654991_Leading_voices_Dialogue_semantics_cognitive_science_and_the_polyphonic_structure_of_multimodal_interaction" target="_blank">Preprint</a>)</p>
											<p>Multimodal communication from a dialogue semantic point of view, formulates the <em>multimodal serialization hypothesis</em> and questions turn organization.</p>
										</article>
										
										<article><p>Andy Lücking and Jonathan Ginzburg. <strong>Referential transparency as the proper treatment of quantification</strong>. In: Semantics and Pragmatics 15, 4 (2022). DOI: <a href="https://doi.org/10.3765/sp.15.4" target="_blank">10.3765/sp.15.4</a>. (<a href="https://semprag.org/index.php/sp/article/view/sp.15.4" target="_blank">Early access</a>)</p>
										<p>A dialogue- and gesture-friendly theory of quantification; with new perspectives on noun phrase negation and complement set anaphora.</p>
										</article>
										
<!--										<article><p>Andy Lücking. <strong>Gesture</strong>. In: Head Driven Phrase Structure Grammar: The handbook. Ed. by Stefan Müller, Anne Abeillé, Robert D. Borsley and Jean-Pierre Koenig. Empirically Oriented Theoretical Morphology and Syntax 9. Berlin: Language Science Press, 2021. Chap. 27, pp. 1201&ndash;1250. DOI: <a href="https://doi.org/10.5281/zenodo.5543318" target="_blank">10.5281/zenodo.5543318</a>. URL: <a href="https://langsci-press.org/catalog/book/259" target="_blank">https://langsci-press.org/catalog/book/259</a>.</p>	
									</article>-->

									<!--<article><p>Andy Lücking, Jonathan Ginzburg and Robin Cooper. <strong>Grammar in dialogue</strong>. In: Head Driven Phrase Structure Grammar: The handbook. Ed. by Stefan Müller, Anne Abeillé, Robert D. Borsley and Jean-Pierre Koenig. Empirically Oriented Theoretical Morphology and Syntax 9. Berlin: Language Science Press, 2021. Chap. 26, pp. 1155&ndash;1199. DOI: <a href="https://doi.org/10.5281/zenodo.5543318" target="_blank">10.5281/zenodo.5543318</a>. URL: <a href="https://langsci-press.org/catalog/book/259" target="_blank">https://langsci-press.org/catalog/book/259</a>.</p></article>-->
									
									<article><p>Jonathan Ginzburg and Andy Lücking. <strong>I thought pointing is rude: A dialogue-semantic analysis of pointing at the addressee</strong>. In: Proceedings of Sinn und Bedeutung 25. Ed. by Patrick Grosz, Luisa Martí, Hazel Pearson, Yasutada Sudo and Sarah Zobel. SuB 25. Special Session: Gestures and Natural Language Semantics. University College London (Online), 2021, pp. 276&ndash;291. URL: <a href="https:
//ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/937" target="_blank">https:
//ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/937</a>.</p>
									<p>Analysing discourse pointing.</p>
									</article>

									<article><p>Jonathan Ginzburg and Andy Lücking. <strong>On Laughter and Forgetting and Reconversing: A neurologically-inspired model of conversational context</strong>. In: Proceedings of the 24th Workshop on the Semantics and Pragmatics of Dialogue. SemDial/WatchDial. Brandeis University, Waltham, New Jersey (Online), 2020. URL: <a href="http://semdial.org/anthology/Z20-Ginzburg_semdial_0008.pdf" target="_blank">http://semdial.org/anthology/Z20-Ginzburg_semdial_0008.pdf</a>.</p>
									<p>Context in dialogue semantics is memory structures.</p>
									</article>
									
									<article><p>Andy Lücking. <strong>Witness-loaded and Witness-free Demonstratives</strong>. In: Atypical Demonstratives. Syntax, Semantics and Pragmatics. Ed. by Marco Coniglio, Andrew Murphy, Eva Schlachter and Tonjes Veenstra. Linguistische Arbeiten 568. Berlin und Boston: De Gruyter, 2018, pp. 255&ndash;284. (<a href="https://www.researchgate.net/publication/303667514_Witness-loaded_and_Witness-free_Demonstratives" target="_blank">Preprint</a>)</p>
									<p>Demonstration acts as search instructions.</p></article>
									
									<article><p>Andy Lücking, Thies Pfeiffer and Hannes Rieser. <strong>Pointing and Reference Reconsidered</strong>. In: Journal of Pragmatics 77 (2015), pp. 56&ndash;79. DOI: <a href="https:doi.org/10.1016/j.pragma.2014.12.013" target="_blank">10.1016/j.pragma.2014.12.013</a>.</p>
									<p>There is no such thing as direct reference...</p></article>
											
											<!--							
									<article><p>Andy Lücking. <strong>Ikonische Gesten. Grundzüge einer linguistischen Theorie</strong>. Berlin and Boston: De Gruyter, 2013.</p>
									<p>Grounding iconic gesture meaning in semantic models by means of exemplification; connects gesture meaning to cognitive representations by means of psychophysics; sets up a phonetic-kinematic gesture interface in grammar.</p></article>
									-->
									
									<article><p>Andy Lücking, Sebastian Ptock and Kirsten Bergmann. <strong>Assessing Agreement on Segmentations by Means of Staccato, the Segmentation Agreement Calculator according to Thomann</strong>. In: Gesture and Sign Language in Human-Computer Interaction and Embodied Communication. 9th International Gesture Workshop, GW 2011, Athens, Greece, May 2011, Revised Selected Papers. Ed. by Eleni Efthimiou, Georgios Kouroupetroglou and Stavroula-Evita Fotina. Lecture Notes in Artificial Intelligence 7206. Berlin und Heidelberg: Springer, 2012, pp. 129&ndash;138. DOI: <a href="https://doi.org/10.1007/978-3-642-34182-3_12" target="_blank">10.1007/978-3-642-34182-3_12</a>.</p><p>A procedure and a tool to assess agreement on markings; Staccato is installed in the video annotation tool <a href="https://archive.mpi.nl/tla/elan" target="_blank">ELAN</a>.</p></article>

									<article><p>Andy Lücking, Kirsten Bergmann, Florian Hahn, Stefan Kopp and Hannes Rieser. <strong>The Bielefeld Speech and Gesture Alignment Corpus (SaGA)</strong>. In: Multimodal Corpora: Advances in Capturing, Coding and Analyzing Multimodality. LREC 2010. 7th International Conference for Language Resources und Evaluation. Malta, 2010, pp. 92&ndash;98. DOI: <a href="https://doi.org/10.13140/2.1.4216.1922" target="_blank">10.13140/2.1.4216.1922</a>.</p></article>

									<article><p>Andy Lücking, Alexander Mehler and Peter Menke. <strong>Taking Fingerprints of Speech-and-Gesture Ensembles: Approaching Empirical Evidence of Intrapersonal Alignmnent in Multimodal Communication</strong>. In: Proceedings of the 12th Workshop on the Semantics and Pragmatics of Dialogue. LonDial'08. King’s College London, 2008, pp. 157&ndash;164. URL: <a href="http://semdial.org/anthology/Z08-Lucking_semdial_0026.pdf" target="_blank">http://semdial.org/anthology/Z08-Lucking_semdial_0026.pdf</a>.</p><p>Recurrent speech&ndash;gestures pairs undergo changes in form.</p></article>
									</div>
								</section>
		
								
								

							<!-- Section -->
								<section>
									<header class="major">
										<h2 id="courses">Workshops</h2>
									</header>
									<div class="features">
										<article>
											<span class="icon solid fa-bezier-curve"></span>
											<div class="content">
												<h3>Upcoming: ESSLLI 2025</h3>
												<p>Workshop <a href="https://aluecking.github.io/ESSLLI2025/" target="_blank">Spatial Gesture Semantics</a>, advanced course at ESSLLI 2025, Ruhr University Bochum, Germany, July 28&ndash;August 8.</p>
											</div>
										</article>
										<article>
											<span class="icon solid fa-hands"></span>
											<div class="content">
												<h3>ESSLLI 2022</h3>
												<p>Workshop <a href="https://aluecking.github.io/ESSLLI2022/" target="_blank">Multimodal Interaction in Dialogue and its Meaning</a> at ESSLLI 2022, Galway, Ireland, August 15&ndash;19 (with <a href="https://sites.google.com/site/jonathanginzburgswebsite/" target="_blank">Jonathan Ginzburg</a>).</p>
											</div>
										</article>
										<article>
											<span class="icon solid fa-brain"></span>
											<div class="content">
												<h3>NASSLLI 2022</h3>
												<p>Workshop <a href="https://aluecking.github.io/NASSLLI2022/" target="_blank">Dialogue across the lifespan</a> at NASSLLI 2022, USC, LA, June 20&ndash;24 (with <a href="https://sites.google.com/site/jonathanginzburgswebsite/" target="_blank">Jonathan Ginzburg</a>).</p>
											</div>
										</article>
										<article>
											<span class="icon solid fa-university"></span>
											<div class="content">
												<h3>Dublin 2004</h3>
												<p><i>A first session with the LKB system</i> at Trinity College, Dublin (with <a href="https://www.researchgate.net/profile/Hannes-Rieser" target="_blank">Hannes Rieser</a>).</p>
											</div>
										</article>
									</div>
								</section>
								
								


								<!-- Section -->
								<section>
									<header class="major">
										<h2 id="talks">Presentations</h2>		
										<p>A few presentations which cover some work on gestures, quantification and alignment. The presentations also cover material on the spatial semantics of pointing gestures and repercussions on deferred reference, which is still not published properly...</p>				
									</header>
									<div class="posts">
									
										<article>
										<a href="./files/LangColloq_Bochum_2022_pointing.pdf" class="image"><img class="titleslide" src="./images/LangColloq_Bochum_2022_pointing-001.png" alt="" style="width: 50%"/></a>
											<p><b>Pointing: From reference to attention and back.</b> Invited talk given at the <i>Bochum Language Colloquium</i>, May 3, 2022 <b><a href="./files/LangColloq_Bochum_2022_pointing.pdf">[PDF]</a></b></p>
										</article>

										<article>
										<a href="./files/discourse-pointing-sub2020.pdf" class="image"><img class="titleslide" src="./images/discourse-pointing-sub2020-01.png" alt="" style="width: 40%"/></a>
											<p><b>I thought pointing is rude: A dialogue-semantic analysis of pointing at the addressee.</b> Talk given at <i>Sinn und Bedeutung 25</i>, Sept. 01&ndash;02, 2020, Workshop on Gestures and Natural Language Semantics <b><a href="./files/discourse-pointing-sub2020.pdf">[PDF]</a></b></p>
										</article>			
			
										<article>
										<a href="./files/clasp18-cleaned.pdf" class="image"><img class="titleslide" src="./images/clasp18-cleaned-001.png" alt="" style="width: 50%" /></a>
											<p><b>Turning context into meaning.</b> Invited talk given at the <i>Centre for Linguistic Theory and Studies in Probability</i> (CLASP), Gothenburg University, December 11th, 2018 <b><a href="./files/clasp18-cleaned.pdf">[PDF]</a></b></p>
										</article>
										
										<article>
										<a href="./files/SanJose-Talk-2011.pdf" class="image"><img class="titleslide" src="./images/SanJose-Talk-2011-01.png" alt="" style="width: 40%" /></a>
											<p><b>From Neural Activation to Symbolic Alignment.</b> Talk given at the <i>International Joint Conference on Neural Networks</i>, San Jose, California, July 31&ndash;August 5, 2011 <b><a href="./files/SanJose-Talk-2011.pdf">[PDF]</a></b></p>
										</article>
									</div>
								</section>



								<!-- Section -->
								<section>
									<header class="major"><h2 id="grammar">On Grammar</h2></header>
									<p>Grammars&mdash;interfaces between phonology, morphology, syntax and semantics&mdash;are the backbones of linguistic research. Accordingly, grammars play an important role in my work, too. This includes multimodal grammar extensions, as developed in my book <a href="https://www.degruyter.com/document/doi/10.1515/9783110301489/html" target="_blank"><i>Ikonische Gesten</i></a>, as well as dialogue interfaces, as outlined in the handbook chapter <a href="https://langsci-press.org/catalog/book/259" target="_blank"><i>Grammar in dialogue</i></a> (available at the publisher's website). Meanwhile, this grammar work has been extended by the plural and quantifier theory <a href="https://doi.org/10.3765/sp.15.4" target="_blank"><i>RTT</i></a>. Since the grammar fragment that implements RTT was a bit too much to be included in the main article, I put it <a href="./files/rtt_grammar_fragment.pdf" >here</a>.</p>
								</section>



								<!-- Section -->
								<section>
									<header class="major">
										<h2 id="projects">Projects</h2>
									</header>
									<div class="posts">
										<article>
											<a href="#" class="image"><img src="images/vr-move.jpg" alt="" /></a>
											<p style="font-size:9px">CC BY-SA 4.0, digmedia.lucdh.nl</p>
											<h3>GeMDiS</h3>
											<p><strong>Virtual Reality Sustained Multimodal Distributional Semantics for Gestures in Dialogue (GeMDiS)</strong>.</p> 
											<p>Due to a lack of apt corpora, "multimodal linguistics" and dialogue theory cannot participate in established distributional methods of corpus linguistics and computational semantics. The main reason for this is the difficulty of collecting multimodal data in an appropriate way and at an appropriate scale. Using the latest VR-based recording methods, the GeMDiS project aims to close this data gap and to investigate visual communication by means of machine-based methods and innovative use of neuronal and active learning for small data using the systematic reference dimensions of associativity and contiguity of the features of visual and non-visual communicative signs.</p>
											<p>GeMDiS is part of the DFG priority programme <a href="https://vicom.info/" target="_blank">Visual Communication</a>.</p>
											<ul class="actions">
												<li><a href="https://vicom.info/virtual-reality-sustained-multimodal-distributional-semantics-for-gestures-in-dialogue-gemdis/" target="_blank" class="button">More</a></li>
											</ul>
										</article>
									</div>
								</section>

						</div>
					</div>
					
					
					
				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
							<!--	<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>
							-->
							
							
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="#publications">Publications</a></li>
										<li><a href="#courses">Workshops</a></li>
										<li><a href="#talks">Presentations</a></li>
										<li><a href="#grammar">On Grammar</a></li>
										<li><a href="#projects">Projects</a></li>
									</ul>
								</nav>



							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="mailto:luecking@em.uni-frankfurt.de">luecking@em.uni-frankfurt.de</a></li>
<!--										<li class="icon solid fa-envelope"><a href="mailto:andy.luecking@u-paris.fr" >andy.luecking@u-paris.fr</a></li> -->
										<li class="icon solid fa-home">Goethe University Frankfurt<br />
										Text Technology Lab<br />
										Robert-Mayer-Straße 10<br />
										60325 Frankfurt am Main, Germany<br />
										<a href="https://www.texttechnologylab.org/team/andy-luecking/" target="_blank">https://www.texttechnologylab.org/team/andy-luecking/</a></li>
<!--										<li class="icon solid fa-home">Université Paris Cité<br />
										Laboratoire de Linguistique Formelle<br />
										5 Rue Thomas Mann<br /> 
										75013 Paris, France<br />
										<a href="http://www.llf.cnrs.fr/fr/Gens/L%C3%BCcking" target="_blank">http://www.llf.cnrs.fr/fr/Gens/L%C3%BCcking</a></li> -->
									</ul>
								</section>



							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Andy Lücking. All rights reserved. CC0. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>
						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>